{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e972a7-f4d4-42c5-9d5e-b12a8a8be9ac",
   "metadata": {},
   "source": [
    "# Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90e78048-6d94-4c2d-b595-3d4687f0b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, InceptionV3, Xception, InceptionResNetV2, ResNet101\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922228e-b705-4496-ba8a-b4f105a94269",
   "metadata": {},
   "source": [
    "### Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a87cc5f4-5e22-4f04-9217-4ec9b0ed3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen_aug = ImageDataGenerator(rescale = 1/255.,\n",
    "                                   shear_range = 0.1, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True, \n",
    "                                   vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e55fa7d-29a4-4ae6-a9f0-89ff4c8bf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_aug = test_gen_aug.flow_from_directory('/Users/annafunsten/Desktop/dsir-322/capstone/Ear-Infection-Identifier/data/middle_ear_images_2/test/', shuffle = False, target_size = (299,299))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7e4ea-7745-468e-bdcc-5e2d6b460844",
   "metadata": {},
   "source": [
    "## Production Model: Model 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3256d150-d98c-4fcf-ab05-e2ddc8070d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = tf.keras.models.load_model('../streamlit_and_models/model12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ce745d-5f67-4632-a288-41bbb0f67115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 531ms/step - loss: 0.6991 - accuracy: 0.7237 - recall: 0.6974 - precision: 0.7794\n"
     ]
    }
   ],
   "source": [
    "results = model12.evaluate(test_data_aug)\n",
    "\n",
    "preds12 = model12.predict(test_data_aug)\n",
    "preds12 = np.argmax(preds12, axis=1)\n",
    "\n",
    "test_data_values = test_data_aug.labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "414d77fb-e8e1-4a75-990a-acf6b11cfb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              effusion  normal  otitis_media  tube\n",
      "effusion             3       2             1     1\n",
      "normal               7      24             2     1\n",
      "otitis_media         0       1            14     1\n",
      "tube                 0       2             1    16\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_data_values, preds12)\n",
    "print(pd.DataFrame(cm, index = ['effusion','normal', 'otitis_media', 'tube'], columns = [ 'effusion' ,'normal', 'otitis_media', 'tube']))\n",
    "#Confusion Matrix\n",
    "#Row is True Class \n",
    "#Column is Predicted Class \n",
    "#Diag Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e97ae38f-9273-4e26-9181-7652ffdc300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    effusion       0.30      0.43      0.35         7\n",
      "      normal       0.83      0.71      0.76        34\n",
      "otitis_media       0.78      0.88      0.82        16\n",
      "        tube       0.84      0.84      0.84        19\n",
      "\n",
      "    accuracy                           0.75        76\n",
      "   macro avg       0.69      0.71      0.70        76\n",
      "weighted avg       0.77      0.75      0.76        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data_values, preds12, target_names = ['effusion', 'normal', 'otitis_media', 'tube']))\n",
    "#F1 Score is the 2*((precision*recall)/(precision+recall)) \n",
    "#TP/(TP+FP)\n",
    "#TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84f350-7903-4fbc-93ed-dd0506118bdd",
   "metadata": {},
   "source": [
    "### Trial of Test Set Images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7850f29-ed59-4ace-95b2-9382a5b7f5b5",
   "metadata": {},
   "source": [
    "### Otitis Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca05133-f3b9-4800-ae0e-8a805e204311",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/annafunsten/Desktop/dsir-322/capstone/Ear-Infection-Identifier/data/middle_ear_images_2/test/03_otitis_media/OT082340.jpg\"\n",
    "\n",
    "test = image.load_img(path, target_size=(299, 299))\n",
    "test\n",
    "\n",
    "pred = model.predict(np.asarray(test).reshape(1, 299, 299, 3))\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
